{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Detection Console\n",
    "\n",
    "Console template created on May 23 2014, class taken from the SciPy 2015 Vispy talk opening example <br>\n",
    "see https://github.com/vispy/vispy/pull/928 https://github.com/flothesof/LiveFFTPitchTracker @author: florian <br>\n",
    "\n",
    "librosa: https://librosa.github.io/librosa/generated/librosa.feature.chroma_cqt.html#librosa.feature.chroma_cqt <br>\n",
    "\n",
    "\n",
    "## HYPERPARAMETERS in the program \n",
    "(not necessarily easily changed)\n",
    "* chunksize\n",
    "elaborated in class MicrophoneRecorder\n",
    "* noise (for energy) \n",
    "determines the onset detection desensitivity\n",
    "* threshold crossing point \n",
    "determines the onset detection sensitivity\n",
    "* lower threshold of spectrum \n",
    "muting everything below the frequency\n",
    "\n",
    "## ISSUES:\n",
    "* lost frames, especially after updating graph \n",
    "I have no idea how to make the plotting happen on a separate thread\n",
    "\n",
    "* harmonic problem:\n",
    "lower frequencies: identifies the second harmonic as ffreq <br>\n",
    "higher frequencies: identifies half of ffreq as ffreq <br>\n",
    "no note may be identified if the drum and piano is hit at the same time <br>\n",
    "\n",
    "## TO DO LIST:\n",
    "* easier on-off switches\n",
    "* display every frame\n",
    "* exclude inharmonic sounds\n",
    "* subtracting the spectrum before the onset\n",
    "* multiplying the signal to analyse with a window\n",
    "* changing some terminologies: \"shift\" to \"delay\"\n",
    "* add some weights, adapt spread adapt spread based on how high ffreq is\n",
    "* implement new pitch (identify region) precise pitch (specify point) HPS to improve the alogrithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import threading\n",
    "import atexit\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PyQt4 import QtGui, uic, QtCore\n",
    "from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib.backends.backend_qt4agg import NavigationToolbar2QT as NavigationToolbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interfacing with the microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MicrophoneRecorder(object):\n",
    "    \"\"\"\n",
    "    This microphone runs on an independent thread.\n",
    "    It groups the signal in blocks of 2048 (chunksize) entries, as \"frame\"\n",
    "    It accumulate these frames until \"get_frames\" is called, when it will pass over these entries.\n",
    "    (There should be no accumulation of entries, else information is lost.)\n",
    "    Choice of chunksize\n",
    "    - large enough to determine the exact frequency\n",
    "    - small enough to be responsive: to indicate the new note as promptly as possible\n",
    "    \"\"\"\n",
    "    def __init__(self, rate=44100, chunksize=2048):\n",
    "        the_input_device_index = 1  # to choose the microphone\n",
    "        self.rate = rate  # sampling rate of microphone\n",
    "        self.chunksize = chunksize  # size of each \"frames\"\n",
    "        self.p = pyaudio.PyAudio()  # imported object to interface with the microphone\n",
    "        self.stream = self.p.open(format=pyaudio.paInt16,  # sound take the format of int16\n",
    "                                  channels=1,  # takes mono?\n",
    "                                  rate=self.rate,  # sampling rate\n",
    "                                  input=True,\n",
    "                                  input_device_index=the_input_device_index,  # to choose the microphone\n",
    "                                  frames_per_buffer=self.chunksize,  # size of each \"frame\"\n",
    "                                  stream_callback=self.new_frame)  # function to call per \"frame\" generated\n",
    "        print self.p.get_device_info_by_index(the_input_device_index)[\"name\"]  # print mic name\n",
    "        \n",
    "        self.lock = threading.Lock()  # something to do with threading\n",
    "        self.stop = False\n",
    "        self.frames = []  # initiatlize frames\n",
    "        atexit.register(self.close)\n",
    "\n",
    "    def new_frame(self, data, frame_count, time_info, status):\n",
    "        \"\"\"\n",
    "        function to call per \"frame\" generated\n",
    "        each frame has \"data\"\n",
    "        \"\"\"\n",
    "        data = np.fromstring(data, 'int16')\n",
    "        with self.lock:  # using threading?\n",
    "            self.frames.append(data)  # add data to the array of \"frames\"\n",
    "            if self.stop:\n",
    "                return None, pyaudio.paComplete\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def get_frames(self):\n",
    "        with self.lock:  # using threading?\n",
    "            frames = self.frames  # return the frames accumulated - should have only one\n",
    "            self.frames = []  # clear frames\n",
    "            return frames\n",
    "\n",
    "    def start(self):\n",
    "        self.stream.start_stream()  # opening recording stream\n",
    "\n",
    "    def close(self):  # some closing procedure, perhaps to erase memory\n",
    "        with self.lock:\n",
    "            self.stop = True\n",
    "        self.stream.close()\n",
    "        self.p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interfacing with the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MplFigure(object):  # don't know what is this for\n",
    "    def __init__(self, parent):\n",
    "        self.figure = plt.figure(facecolor='white')\n",
    "        self.canvas = FigureCanvas(self.figure)\n",
    "        self.toolbar = NavigationToolbar(self.canvas, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LiveFFTWidget(QtGui.QWidget):\n",
    "    def __init__(self):\n",
    "        QtGui.QWidget.__init__(self)\n",
    "\n",
    "        self.chunksize = 2048\n",
    "        self.tempo_res = 32  # r_coeff resolution, needs to be a factor of chunksize\n",
    "        self.tempo_num = int(self.chunksize/self.tempo_res)\n",
    "        self.iteration = 0  # for counting, if needed\n",
    "        self.noise = np.round(200000*np.random.randn(self.chunksize))  # to desensitise onset detection\n",
    "        self.sampling_rate = 44100\n",
    "        self.notes_dict = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "        \n",
    "        # holding variables, initialised with something random \n",
    "        \n",
    "        self.signal_frame_pp0 = self.noise\n",
    "        self.signal_frame_pp1 = self.noise\n",
    "        self.signal_frame_pp2 = self.noise\n",
    "        self.signal_frame_pp3 = self.noise\n",
    "        \n",
    "        self.energy_frame_pp0 = self.noise\n",
    "        self.energy_frame_pp1 = self.noise\n",
    "        self.energy_frame_pp2 = self.noise\n",
    "        self.energy_frame_pp3 = self.noise\n",
    "        \n",
    "        self.rcoeff_frame_pp1 = [0.0] * int(self.tempo_res)\n",
    "        self.rcoeff_frame_pp2 = [0.0] * int(self.tempo_res)\n",
    "        self.rcoeff_frame_pp3 = [0.0] * int(self.tempo_res)\n",
    "        \n",
    "        self.bar_duration = 2.0  # how long your bar lasts\n",
    "        self.bar_current = 0\n",
    "        self.bar_cleared = 0\n",
    "        self.loudness = 0\n",
    "        self.bar_0_offsets = []\n",
    "        self.bar_0_sizes = []\n",
    "        self.bar_1_offsets = []\n",
    "        self.bar_1_sizes = []\n",
    "        self.bar_2_offsets = []\n",
    "        self.bar_2_sizes = []\n",
    "        self.bar_3_offsets = []\n",
    "        self.bar_3_sizes = []\n",
    "        \n",
    "        self.note_detected = False\n",
    "        self.note = \"N.A.\"\n",
    "        self.ffreq = 0.0\n",
    "        self.signal_to_show = [0] * (self.chunksize*2)\n",
    "        self.signal_to_ayse = [0] * (self.chunksize)\n",
    "        self.shift = 0.0  # affects the part of the signal that will be analysed and plotted\n",
    "        # customize the UI\n",
    "        self.initUI()\n",
    "\n",
    "        # init class data\n",
    "        self.initData()\n",
    "\n",
    "        # connect slots\n",
    "        self.connectSlots()  # don't know what is this for\n",
    "\n",
    "        # init MPL widget\n",
    "        self.initMplWidget()  # (refer to MplFigure class)\n",
    "\n",
    "        self.start_time = time.time()  # start timer\n",
    "        self.prev_time = time.time()  # to calculate the time difference\n",
    "#\n",
    "        self.current_time = self.start_time\n",
    "\n",
    "    def initUI(self):  # comment on this later\n",
    "        hbox_gain = QtGui.QHBoxLayout()\n",
    "        autoGain = QtGui.QLabel('Auto gain')\n",
    "        autoGainCheckBox = QtGui.QCheckBox(checked=True)\n",
    "        hbox_gain.addWidget(autoGain)\n",
    "        hbox_gain.addWidget(autoGainCheckBox)\n",
    "\n",
    "        # reference to checkbox\n",
    "        self.autoGainCheckBox = autoGainCheckBox\n",
    "\n",
    "        hbox_fixedGain = QtGui.QHBoxLayout()\n",
    "        fixedGain = QtGui.QLabel('Fixed gain level')\n",
    "        fixedGainSlider = QtGui.QSlider(QtCore.Qt.Horizontal)\n",
    "        hbox_fixedGain.addWidget(fixedGain)\n",
    "        hbox_fixedGain.addWidget(fixedGainSlider)\n",
    "\n",
    "        self.fixedGainSlider = fixedGainSlider\n",
    "\n",
    "        vbox = QtGui.QVBoxLayout()\n",
    "\n",
    "        vbox.addLayout(hbox_gain)\n",
    "        vbox.addLayout(hbox_fixedGain)\n",
    "\n",
    "        # mpl figure\n",
    "        self.main_figure = MplFigure(self)\n",
    "        vbox.addWidget(self.main_figure.toolbar)\n",
    "        vbox.addWidget(self.main_figure.canvas)\n",
    "\n",
    "        self.setLayout(vbox)\n",
    "\n",
    "        self.setGeometry(300, 300, 350, 300)\n",
    "        self.setWindowTitle('LiveFFT')\n",
    "        self.show()\n",
    "\n",
    "        # timer for calls, taken from:\n",
    "        # http://ralsina.me/weblog/posts/BB974.html\n",
    "        timer = QtCore.QTimer()\n",
    "        timer.timeout.connect(self.handleNewData)  # calls handleNewData every 20ms\n",
    "        timer.start(10)  # chunks come out at a frequency of approximately 46ms\n",
    "        # keep reference to timer\n",
    "        self.timer = timer\n",
    "\n",
    "    def initData(self):\n",
    "        mic = MicrophoneRecorder(rate=44100, chunksize=self.chunksize)\n",
    "        mic.start()\n",
    "\n",
    "        # keeps reference to mic\n",
    "        self.mic = mic\n",
    "\n",
    "        # computes the parameters that will be used during plotting\n",
    "        self.freq_vect = np.fft.rfftfreq(mic.chunksize, 1./mic.rate)  # original\n",
    "        self.time_vect = np.arange(-mic.chunksize, mic.chunksize, dtype=np.float32) / mic.rate * 1000\n",
    "        self.score_vect = np.arange(0, 4) #PCPS\n",
    "        # the onset will be in the middle\n",
    "\n",
    "    def connectSlots(self):\n",
    "        pass  # don't know what is this for\n",
    "\n",
    "    def initMplWidget(self):\n",
    "        \"\"\"\n",
    "        creates initial matplotlib plots in the main window and keeps references for further use\n",
    "        \"\"\"\n",
    "#         # top plot: currently to show energy\n",
    "#         self.ax_top = self.main_figure.figure.add_subplot(211)\n",
    "#         self.ax_top.set_ylim(-32768, 32768)  # original\n",
    "#         # self.ax_top.set_ylim(-32768 * 100, 32768 * 100)  # to show energy\n",
    "#         self.ax_top.set_xlim(self.time_vect.min(), self.time_vect.max())\n",
    "#         self.ax_top.set_xlabel(u'time (ms)', fontsize=6)\n",
    "        \n",
    "        # top plot: now showing score and where you hit\n",
    "        self.ax_top = self.main_figure.figure.add_subplot(211)\n",
    "        self.ax_top.set_ylim(-3, 15)  # original\n",
    "        self.ax_top.set_xlim(0, 4)\n",
    "        self.ax_top.set_xlabel(u'bar number', fontsize=6)\n",
    "\n",
    "        # bottom plot: currently to show spectrum\n",
    "        self.ax_bottom = self.main_figure.figure.add_subplot(212)\n",
    "        self.ax_bottom.set_ylim(0, 1)\n",
    "        # self.ax_bottom.set_xlim(0, self.freq_vect.max()) original\n",
    "        self.ax_bottom.set_xlim(0, 5000.)\n",
    "        self.ax_bottom.set_xlabel(u'frequency (Hz)', fontsize=6)\n",
    "\n",
    "        # line objects\n",
    "#         self.line_top, = self.ax_top.plot(self.time_vect,\n",
    "#                                           np.ones_like(self.time_vect), lw=0.2)\n",
    "        \n",
    "        self.bar_0 = self.ax_top.scatter([], [], s = [], edgecolors='none')\n",
    "        self.bar_1 = self.ax_top.scatter([], [], s = [], edgecolors='none')\n",
    "        self.bar_2 = self.ax_top.scatter([], [], s = [], edgecolors='none')\n",
    "        self.bar_3 = self.ax_top.scatter([], [], s = [], edgecolors='none')\n",
    "        \n",
    "        self.line_bottom, = self.ax_bottom.plot(self.freq_vect,\n",
    "                                                np.ones_like(self.freq_vect), lw=0.5)\n",
    "\n",
    "        self.pitch_line, = self.ax_bottom.plot((self.freq_vect[self.freq_vect.size / 2],\n",
    "                                                self.freq_vect[self.freq_vect.size / 2]),\n",
    "                                               self.ax_bottom.get_ylim(), lw=2)\n",
    "        # This plots for vertical line that marks the pitch\n",
    "        # plt.tight_layout()  # tight layout\n",
    "\n",
    "    def handleNewData(self):\n",
    "        \"\"\" handles the asynchronously collected sound chunks \"\"\"\n",
    "#\n",
    "        if self.iteration == 0:\n",
    "            self.start_time = time.time()  # set to the true start time    \n",
    "        \n",
    "#         print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "#         \" gets the latest frames\"\n",
    "#         self.prev_time = time.time()\n",
    "        signal_frames = self.mic.get_frames()\n",
    "\n",
    "        # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "        # \" taking last frame\"\n",
    "        # self.prev_time = time.time()\n",
    "        if len(signal_frames) > 0:\n",
    "            if len(signal_frames) > 1:\n",
    "                print str(len(signal_frames) - 1) + \" frame lost\"\n",
    "                # indicate number of frames lost - should not have any\n",
    "            self.signal_frame_pp0 = signal_frames[-1]  # keeps only the last frame\n",
    "            \n",
    "            # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "            # \" energy calculations\"  # 0.01s\n",
    "            # self.prev_time = time.time()\n",
    "            # to calculate the rectangular window for every sample\n",
    "            # numpy operations are more efficient than using python loops\n",
    "            # the size of the rectangular window is one chunksize\n",
    "            # convolution can be considered\n",
    "            self.energy_frame_pp0 = np.full(self.chunksize, sum(np.absolute(self.signal_frame_pp2)), dtype=\"int32\")\n",
    "            to_cumsum = np.add(np.absolute(self.signal_frame_pp1), -np.absolute(self.signal_frame_pp2))\n",
    "            cumsum = np.cumsum(to_cumsum)\n",
    "            self.energy_frame_pp0[1:] = np.add(self.energy_frame_pp0[1:], cumsum[:-1])\n",
    "            self.energy_frame_pp0 = np.add(self.energy_frame_pp0, self.noise)\n",
    "            \n",
    "            # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "            # \" r_coeff calculations\"\n",
    "            # self.prev_time = time.time()\n",
    "            # calculating pearson correlation coefficient at 2048/32 samples\n",
    "            # to determine exact time of onset\n",
    "            # could not think of any way this could be parallelised\n",
    "            energy_arg = np.concatenate((self.energy_frame_pp1, self.energy_frame_pp0))\n",
    "            # energy_arg = np.concatenate((self.energy_frame_pp1[i*self.tempo_num:],\n",
    "            #                              self.energy_frame_pp0[:-(self.tempo_res-i)*self.tempo_num]))\n",
    "            for i in range(self.tempo_res):\n",
    "                self.rcoeff_frame_pp1[i] = np.corrcoef(energy_arg[i*self.tempo_num:(i*self.tempo_num+self.chunksize)],\n",
    "                                                       np.arange(self.chunksize))[0, 1]            \n",
    "            \n",
    "#             print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "#             \" detecting new note\"\n",
    "#             self.prev_time = time.time()\n",
    "            rcoeff_arg = np.concatenate((self.rcoeff_frame_pp2, self.rcoeff_frame_pp1))\n",
    "            # we need the previous rcoeff frame to determine onset\n",
    "\n",
    "            # finding the onset, any way not to loop?\n",
    "#             for i in range(self.tempo_res, 0, -1):\n",
    "            for _ in range(1):\n",
    "#                 if rcoeff_arg[-i] > 0.80 and all(i < 0.80 for i in rcoeff_arg[-i-5:-i]):\n",
    "                # if rcoeff_arg[-i] > 0.80 and np.max(rcoeff_arg[-i-31:-i]) < 0.80:\n",
    "                if True:\n",
    "                    # to determine onset  - where the rcoeff graph crosses 0.80,\n",
    "                    # 31 entries cooldown - check that previous entries do not have cooldown\n",
    "                    # print i\n",
    "                    # print rcoeff_arg[-i]\n",
    "                    # print np.around(rcoeff_arg, 2)\n",
    "\n",
    "                    # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                    # \" note class\"\n",
    "                    # self.prev_time = time.time()\n",
    "                    time_arg = np.concatenate((self.signal_frame_pp3, self.signal_frame_pp2,\n",
    "                                               self.signal_frame_pp1, self.signal_frame_pp0))\n",
    "                    self.signal_to_show = time_arg[-i*self.tempo_num - int((2+self.shift)*self.chunksize):\n",
    "                                                   -i*self.tempo_num - int((0+self.shift)*self.chunksize)]\n",
    "                    self.signal_to_ayse = time_arg[-i*self.tempo_num - int((1+self.shift)*self.chunksize):\n",
    "                                                   -i*self.tempo_num - int((0+self.shift)*self.chunksize)]\n",
    "                    signal_to_deduct = time_arg[-i*self.tempo_num - int((2+self.shift)*self.chunksize):\n",
    "                                                -i*self.tempo_num - int((1+self.shift)*self.chunksize)]\n",
    "                    # Consider whether should a window be applied\n",
    "\n",
    "                    spectrum = np.absolute(np.fft.fft(self.signal_to_ayse))\n",
    "                    spectrum_to_deduct = np.absolute(np.fft.fft(signal_to_deduct))\n",
    "                    to_subtract = False  # take the spectral difference between the current and previous chunk\n",
    "                    if to_subtract:\n",
    "                        spectrum = np.clip(np.add(spectrum, -1 * np.array(spectrum_to_deduct)), 0, 100000000)\n",
    "                        # consider the effectiveness of taking the difference\n",
    "\n",
    "                    # self.spectrum = np.array(spectrum[:int(0.5*self.chunksize)+1])  # to be plotted MOVED TO LATER\n",
    "                    # following is the hps algorithm\n",
    "                    spectrum[:12] = 0.0  # anything below middle C is muted\n",
    "#                     spectrum[:6] = 0.0  # anything below C3 is muted\n",
    "                    spectrum[1024:] = 0.0  # mute second half of spectrum, lazy to change code\n",
    "\n",
    "                    scale1 = [0.0] * (2048 * 6)\n",
    "                    scale2 = [0.0] * (2048 * 6)\n",
    "                    scale3 = [0.0] * (2048 * 6)\n",
    "\n",
    "                    # upsampling the original scale spectrum, 6 for 1\n",
    "                    scale1_f1 = np.convolve(spectrum, [5.0 / 6.0, 1.0 / 6.0])[1:]\n",
    "                    scale1_f2 = np.convolve(spectrum, [4.0 / 6.0, 2.0 / 6.0])[1:]\n",
    "                    scale1_f3 = np.convolve(spectrum, [3.0 / 6.0, 3.0 / 6.0])[1:]\n",
    "                    scale1_f4 = np.convolve(spectrum, [2.0 / 6.0, 4.0 / 6.0])[1:]\n",
    "                    scale1_f5 = np.convolve(spectrum, [1.0 / 6.0, 5.0 / 6.0])[1:]\n",
    "                    scale1[::6] = spectrum\n",
    "                    scale1[1::6] = scale1_f5\n",
    "                    scale1[2::6] = scale1_f4\n",
    "                    scale1[3::6] = scale1_f3\n",
    "                    scale1[4::6] = scale1_f2\n",
    "                    scale1[5::6] = scale1_f1\n",
    "                    # downsampling from the 6 for 1 upsample\n",
    "                    scale2[:2048 * 3] = scale1[::2]\n",
    "                    scale3[:2048 * 2] = scale1[::3]\n",
    "                    hps = np.prod((scale1, scale2, scale3), axis=0)  # the \"product\" in harmonic product spectrum\n",
    "                    hps_max = np.argmax(hps)  # determine the location of the peak of hps result\n",
    "                    # calculate the corresponding frequency of the peak\n",
    "                    self.ffreq = hps_max * 44100.0 / (2048.0 * 6.0)  # sampling rate / (chunksize * upsampling value)\n",
    "\n",
    "                    self.spectrum = np.array(spectrum[:int(0.5*self.chunksize)+1])  # to be plotted MOVED FROM EARILER\n",
    "\n",
    "                    if hps_max < 5:\n",
    "                        print \"low ffreq\"  # should not be possible - just investigating\n",
    "                        break\n",
    "\n",
    "                    # TODO: add some weights, adapt spread based on how high ffreq is\n",
    "                    total_energy = np.sum(scale1)\n",
    "                    total_energy_due_to_ffreq = np.sum(scale1[::hps_max]) \\\n",
    "                                                + np.sum(scale1[1::hps_max]) + np.sum(scale1[:hps_max - 1:hps_max]) \\\n",
    "                                                # + np.sum(scale1[2::hps_max]) + np.sum(scale1[:hps_max - 2:hps_max]) \\\n",
    "                                                # + np.sum(scale1[3::hps_max]) + np.sum(scale1[:hps_max - 3:hps_max]) \\\n",
    "                                                # + np.sum(scale1[4::hps_max]) + np.sum(scale1[:hps_max - 4:hps_max]) \\\n",
    "                                                # + np.sum(scale1[5::hps_max]) + np.sum(scale1[:hps_max - 5:hps_max]) \\\n",
    "                                                # + np.sum(scale1[6::hps_max]) + np.sum(scale1[:hps_max - 6:hps_max])\n",
    "#\n",
    "                    self.loudness = total_energy_due_to_ffreq  # exported for plotting the bar chart\n",
    "                                            \n",
    "                    portion_of_energy = (total_energy_due_to_ffreq/total_energy)*20\n",
    "\n",
    "#                     if portion_of_energy > 1:\n",
    "                    if True:\n",
    "                        # printing note in solfage form\n",
    "                        note_no = -3 + (np.log2(self.ffreq) - np.log2(220.0)) * 12.0  # take logarithm and find note\n",
    "#                         note_no = -3 + (np.log2(self.ffreq) - np.log2(110.0)) * 12.0  # take logarithm and find note\n",
    "                        note_no_rounded = np.round(note_no)  # round off to nearest note\n",
    "                        note_no_difference = note_no - note_no_rounded\n",
    "                        octave_no = 4 + int(note_no_rounded // 12)\n",
    "#                         octave_no = 3 + int(note_no_rounded // 12)\n",
    "                        solfate_no = int(note_no_rounded) % 12\n",
    "                        self.note = str(self.notes_dict[solfate_no]) + str(octave_no)\n",
    "                        \n",
    "                        self.note_no = note_no  # exported for later usage\n",
    "                        \n",
    "                        print (\"{:.2f}Hz({:02}) {:.2f}, {:3s} {:+.2f} at {:.3f}s\"\n",
    "                               .format(self.ffreq, int(note_no_rounded), portion_of_energy, self.note, note_no_difference,\n",
    "                                       time.time() - self.start_time))\n",
    "                        self.note_detected = True\n",
    "                    else:\n",
    "#                         print(\"inharmonic sound ({:.2f}) detected at {:.3f}s\"\n",
    "#                               .format(portion_of_energy, time.time() - self.start_time))\n",
    "                        pass\n",
    "\n",
    "            display_only_note = False\n",
    "            if self.note_detected or not display_only_note and self.iteration > 0:  # first loop have ambiguous loudness\n",
    "#                 print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "#                 \" set time on graph\"  # 0.001s\n",
    "#                 self.prev_time = time.time()\n",
    "\n",
    "# \n",
    "#                 self.line_top.set_data(self.time_vect, self.signal_to_show)  # plots the time signal, onset on middle\n",
    "                # self.line_top.set_data(self.time_vect, np.concatenate((self.signal_frame_pp2, self.signal_frame_pp1)))\n",
    "                # self.line_top.set_data(self.time_vect, energy_arg)  # plots the energy\n",
    "#                 self.ax_top.scatter(2 + np.random.randn(), 2 + np.random.randn(), [10])\n",
    "#                 self.bar_1 = self.ax_top.scatter([2 + np.random.randn()], [2 + np.random.randn()], [10])\n",
    "#                 self.bar_1.set_offsets([[2 + np.random.random(), 2 + np.random.random()], \n",
    "#                                         [2 + np.random.random(), 2 + np.random.random()]])\n",
    "#                 self.bar_1.set_sizes([2 + 20*np.random.random(), 2 + 20*np.random.random()])\n",
    "\n",
    "\n",
    "                self.loudness = int(1+self.loudness/100000.)  # need a better function lulz\n",
    "#                 print self.loudness\n",
    "\n",
    "                self.current_time = time.time() - self.start_time                \n",
    "                self.bar_current = np.floor(self.current_time / self.bar_duration)\n",
    "                residual_bar = (self.current_time - (self.bar_current * self.bar_duration))/self.bar_duration\n",
    "#                 print residual_time\n",
    "        \n",
    "                if self.bar_current - self.bar_cleared > 2:\n",
    "                    bar_to_clear = (self.bar_current - 3) % 4\n",
    "                    self.bar_cleared = self.bar_current - 2\n",
    "                    if bar_to_clear == 0:\n",
    "                        self.bar_0_offsets = []\n",
    "                        self.bar_0_sizes = []\n",
    "                        self.bar_0.set_offsets([])\n",
    "                        self.bar_0.set_sizes([])\n",
    "                    elif bar_to_clear == 1:\n",
    "                        self.bar_1_offsets = []\n",
    "                        self.bar_1_sizes = []\n",
    "                        self.bar_1.set_offsets([])\n",
    "                        self.bar_1.set_sizes([])\n",
    "                    elif bar_to_clear == 2:\n",
    "                        self.bar_2_offsets = []\n",
    "                        self.bar_2_sizes = []\n",
    "                        self.bar_2.set_offsets([])\n",
    "                        self.bar_2.set_sizes([])\n",
    "                    elif bar_to_clear == 3:\n",
    "                        self.bar_3_offsets = []\n",
    "                        self.bar_3_sizes = []\n",
    "                        self.bar_3.set_offsets([])\n",
    "                        self.bar_3.set_sizes([])\n",
    "                \n",
    "                if self.bar_current%4 == 0:\n",
    "                    self.bar_0_offsets.append([0 + residual_bar, self.note_no])\n",
    "                    self.bar_0_sizes.append(self.loudness)\n",
    "                    self.bar_0.set_offsets(self.bar_0_offsets)\n",
    "                    self.bar_0.set_sizes(self.bar_0_sizes)\n",
    "                elif self.bar_current%4 == 1:\n",
    "                    self.bar_1_offsets.append([1 + residual_bar, self.note_no])\n",
    "                    self.bar_1_sizes.append(self.loudness)\n",
    "                    self.bar_1.set_offsets(self.bar_1_offsets)\n",
    "                    self.bar_1.set_sizes(self.bar_1_sizes)\n",
    "                elif self.bar_current%4 == 2:\n",
    "                    self.bar_2_offsets.append([2 + residual_bar, self.note_no])\n",
    "                    self.bar_2_sizes.append(self.loudness)\n",
    "                    self.bar_2.set_offsets(self.bar_2_offsets)\n",
    "                    self.bar_2.set_sizes(self.bar_2_sizes)\n",
    "                elif self.bar_current%4 == 3:\n",
    "                    self.bar_3_offsets.append([3 + residual_bar, self.note_no])\n",
    "                    self.bar_3_sizes.append(self.loudness)\n",
    "                    self.bar_3.set_offsets(self.bar_3_offsets)\n",
    "                    self.bar_3.set_sizes(self.bar_3_sizes) \n",
    "                  \n",
    "\n",
    "                # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                # \" take FFT\"\n",
    "                # self.prev_time = time.time()\n",
    "                # fft_frame = self.spectrum\n",
    "                # fft_frame = np.fft.rfft(self.signal_to_ayse)  # computes and plots the fft signal\n",
    "                # print len(fft_frame)\n",
    "                # print len(self.spectrum)\n",
    "                fft_frame = self.spectrum  # 1025 entries\n",
    "\n",
    "                # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                # \" some thing about scaling\"\n",
    "                # self.prev_time = time.time()\n",
    "                # inherited, don't know what is this for\n",
    "                # perhaps it is to normalise the spectrum - plotting is faster without changing axes\n",
    "                if self.autoGainCheckBox.checkState() == QtCore.Qt.Checked:\n",
    "                    fft_frame /= np.abs(fft_frame).max()\n",
    "                else:\n",
    "                    fft_frame *= (1 + self.fixedGainSlider.value()) / 5000000.\n",
    "                    # print(np.abs(fft_frame).max())\n",
    "\n",
    "                # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                # \" set spectrum on graph\"  # 0.001 s\n",
    "                # self.prev_time = time.time()\n",
    "                self.line_bottom.set_data(self.freq_vect, np.abs(fft_frame))\n",
    "\n",
    "                # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                # \" placeholder\"  # 0.8s wdf\n",
    "                # self.prev_time = time.time()\n",
    "\n",
    "                new_pitch = self.ffreq\n",
    "                precise_pitch = self.ffreq\n",
    "\n",
    "                # print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                # \" set pitch on graph\"\n",
    "                # self.prev_time = time.time()\n",
    "                \n",
    "                self.ax_bottom.set_title(\"pitch = {:.2f} Hz ({})\".format(precise_pitch, self.note))\n",
    "                self.pitch_line.set_data((new_pitch, new_pitch),\n",
    "                                         self.ax_bottom.get_ylim())  # move the vertical pitch line\n",
    "\n",
    "                if self.iteration % 1 == 0:  # update plot only after every n chunks, if necessary\n",
    "                    print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                    \" refresh plot\"  # 0.105s\n",
    "                    self.prev_time = time.time()\n",
    "                    self.main_figure.canvas.draw()  # refreshes the plots, takes the bulk of time\n",
    "                    print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "                    \" refreshed plot\"  # 0.105s\n",
    "                    self.prev_time = time.time()    \n",
    "\n",
    "                self.note_detected = False\n",
    "\n",
    "#             print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "#             \" storing for recursion\"\n",
    "#             self.prev_time = time.time()\n",
    "            self.signal_frame_pp3 = self.signal_frame_pp2[:]\n",
    "            self.signal_frame_pp2 = self.signal_frame_pp1[:]\n",
    "            self.signal_frame_pp1 = self.signal_frame_pp0[:]\n",
    "            self.energy_frame_pp1 = self.energy_frame_pp0[:]\n",
    "            self.rcoeff_frame_pp2 = self.rcoeff_frame_pp1[:]\n",
    "\n",
    "        self.iteration += 1\n",
    "        #print str(time.time() - self.start_time) + \"  \" + str(time.time() - self.prev_time) + \\\n",
    "        # \" end of loop \\n \\n\"\n",
    "        # self.prev_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QtGui.QApplication(sys.argv)\n",
    "    window = LiveFFTWidget()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
